{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env OPENAI_API_KEY=<openai-api-keykey>\n",
    "%env LANGCHAIN_TRACING_V2=true\n",
    "%env LANGCHAIN_API_KEY=<langchain-api-key>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "from langsmith import schemas\n",
    "from langchain import load\n",
    "\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset with the training data\n",
    "\n",
    "## Gather the LLM calls from LangSmith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import datetime\n",
    "\n",
    "project_name = \"fine-tuning-example\"\n",
    "run_type = \"llm\"\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "runs = client.list_runs(\n",
    "    project_name=project_name,\n",
    "    run_type=run_type,\n",
    "    error=False,\n",
    ")\n",
    "\n",
    "llm_runs = []\n",
    "for run in runs:\n",
    "    llm_runs.append(run)\n",
    "\n",
    "training_data = llm_runs[:60] # Gets just the last 60, which should be all our data\n",
    "len(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name=\"Fine-Tuning Dataset Example\"\n",
    "dataset = client.create_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    description=f\"Chat logs taken from project {project_name} for fine-tuning\",\n",
    "    data_type=\"chat\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add the data to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "for run in training_data:\n",
    "    if \"messages\" not in run.inputs or not run.outputs:\n",
    "        continue\n",
    "    try:\n",
    "        client.create_example_from_run(\n",
    "            dataset_id=dataset.id,\n",
    "            run=run\n",
    "        )\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning with our data\n",
    "\n",
    "## Conver the messages into a structure that OpenAI can take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "def convert_messages(example: schemas.Example) -> dict:\n",
    "    print(example.outputs)\n",
    "    messages = HumanMessage(content=load.load(example.inputs)[\"input\"][1]['data']['content'])\n",
    "    message_chunk = AIMessage(content=load.load(example.outputs)[\"output\"]['data']['content'])\n",
    "    print(messages)\n",
    "    return {\"messages\": [messages] + [message_chunk]}\n",
    "\n",
    "messages = [\n",
    "    convert_messages(example)\n",
    "    for example in client.list_examples(dataset_name=dataset_name)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'content': \"Provide a customer-facing response for the following review: WidgetWorld's widgets are decent, but nothing exceptional. They get the job done adequately.\\n\\nResponse: \"}, {'role': 'assistant', 'content': \"Arrr, ahoy there matey! Thank ye fer yer review of our widgets at WidgetWorld. We be glad to hear that they be gettin' the job done adequately for ye. If ye ever be needin' any assistance or have any feedback to share, don't hesitate to reach out to us. Fair winds and smooth sailin' to ye!\"}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain.adapters import openai as openai_adapter\n",
    "\n",
    "finetuning_messages = openai_adapter.convert_messages_for_finetuning(messages)\n",
    "\n",
    "print(finetuning_messages[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import io\n",
    "\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "openAiClient = OpenAI()\n",
    "\n",
    "my_file = io.BytesIO()\n",
    "for group in finetuning_messages:\n",
    "    if any([\"function_call\" in message for message in group]):\n",
    "        continue\n",
    "    my_file.write((json.dumps({\"messages\": group}) + \"\\n\").encode(\"utf-8\"))\n",
    "\n",
    "my_file.seek(0)\n",
    "training_file = openAiClient.files.create(file=my_file, purpose=\"fine-tune\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'processed'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "status = openAiClient.files.retrieve(training_file.id).status\n",
    "status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File file-WQKlRPcULSwCLOax1uBluzWf ready after 0.00 seconds.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "while status != \"processed\":\n",
    "    print(f\"Status=[{status}]... {time.time() - start_time:.2f}s\", end=\"\\r\", flush=True)\n",
    "    time.sleep(5)\n",
    "    status = openai.File.retrieve(training_file.id).status\n",
    "print(f\"File {training_file.id} ready after {time.time() - start_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status=[validating_files]... 0.00s\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status=[running]... 539.23s. 31.01s\r"
     ]
    }
   ],
   "source": [
    "job = openAiClient.fine_tuning.jobs.create(\n",
    "    training_file=training_file.id,\n",
    "    model=\"gpt-3.5-turbo-0125\",\n",
    ")\n",
    "\n",
    "# It may take 10-20+ minutes to complete training.\n",
    "status = openAiClient.fine_tuning.jobs.retrieve(job.id).status\n",
    "start_time = time.time()\n",
    "while status != \"succeeded\":\n",
    "    print(f\"Status=[{status}]... {time.time() - start_time:.2f}s\", end=\"\\r\", flush=True)\n",
    "    time.sleep(5)\n",
    "    job = openAiClient.fine_tuning.jobs.retrieve(job.id)\n",
    "    status = job.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ft:gpt-3.5-turbo-0125:xevant::9Q0Hk9G4'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import chat_models, prompts\n",
    "\n",
    "model_name = job.fine_tuned_model\n",
    "model_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Ahoy matey! Thank ye kindly for sharin' yer experience at Widget World. I be thrilled to hear ye had a fantastic time. Arrr, I couldn't agree more that everyone should set sail to Widget World and discover all the wonders it has to offer. Fair winds to ye!\", response_metadata={'token_usage': {'completion_tokens': 60, 'prompt_tokens': 25, 'total_tokens': 85}, 'model_name': 'ft:gpt-3.5-turbo-0125:xevant::9Q0Hk9G4', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-bc9fee78-453b-4fb0-9232-58fb43acac3f-0')"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "model = ChatOpenAI(model=model_name)\n",
    "prompt_template = PromptTemplate(template=\"Provide a response to the following review: {review}\", input_variables=[\"review\"])\n",
    "chain = prompt_template | model\n",
    "chain.invoke({\"review\": \" Widget world was fantastic! Everyone should go.\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Messages fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from reviews import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a customer service agent that talks in a pirate voice'), HumanMessage(content='Provide a customer-facing response for the following review: {review}\\n\\nResponse: ')])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate(tags=[\"reviews\"], messages=[\n",
    "    SystemMessage(content=\"You are a customer service agent that talks in a pirate voice\"),\n",
    "    HumanMessage(content=\"Provide a customer-facing response for the following review: {review}\\n\\nResponse: \")\n",
    "], input_variables=[\"review\"])\n",
    "chain = prompt\n",
    "chain.invoke({\"review\": \"Hello World\"})\n",
    "# for review in reviews:\n",
    "#     chain.invoke({'review': review})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
